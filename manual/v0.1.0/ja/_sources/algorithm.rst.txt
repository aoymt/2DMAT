.. _chap_algorithm:

アルゴリズム
=====================
2DMAT はパラメータ空間上の点 :math:`\vec{x}` から実数値を返すような目的関数 :math:`f(\vec{x})` について、
これを最小化するような最適解 :math:`\vec{x}^* = \mathrm{minarg}_{\vec{x}}f(\vec{x})` を探索します。
前提として、目的関数の導関数は利用できないものとしています。
ここでは、2DMATで用いられている以下の探索アルゴリズムについて説明します。

- ``minsearch``
- ``mapper_mpi``
- ベイズ最適化
- レプリカ交換モンテカルロ法
  
``minsearch``
****************
``minsearch`` は `Nelder-Mead 法 <https://en.wikipedia.org/wiki/Nelder%E2%80%93Mead_method>`_ (a.k.a. downhill simplex 法) によって最適化を行います。
Nelder-Mead 法では、 パラメータ空間の次元を :math:`D` として、 :math:`D+1` 個の座標点の組を、各点での目的関数の値に応じて系統的に動かすことで最適解を探索します。

重要なハイパーパラメータとして、座標の初期値があります。
単純な最急降下法よりは安定ですが、局所最適解にトラップされるという問題は残っているので、初期値を変えた計算を何回か繰り返して結果を確認することをおすすめします。

2DMATは、SciPy の ``scipy.optimize.minimize(method="Nelder-Mead")`` 関数を用いています。
詳しくは `公式ドキュメント <https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize>`_ をご参照ください。


``mapper_mpi``
****************
``mapper_mpi`` はパラメータ空間中の候補点をあらかじめ用意しておいて、そのすべてで :math:`f(x)` を計算することで最小値を探索するアルゴリズムです。
MPI 実行した場合、候補点の集合を等分割して各プロセスに自動的に割り振ることで自明並列計算を行います。


ベイズ最適化
***************

`ベイズ最適化 (Bayesian optimization, BO) <https://en.wikipedia.org/wiki/Bayesian_optimization>`_ は、機械学習を援用した最適化アルゴリズムであり、特に目的関数の評価に時間がかかるときに強力な手法です。

BO では目的関数 :math:`f(\vec{x})` を、評価が早く最適化のしやすいモデル関数（多くの場合ガウス過程） :math:`g(\vec{x})` で近似します。
:math:`g` は、あらかじめ適当に決められたいくつかの点（訓練データセット） :math:`\{\vec{x}_i\}_{i=1}^N` での目的関数の値 :math:`\{f(\vec{x}_i)\}_{i=1}^N` をよく再現するように訓練されます。
パラメータ空間の各点において、訓練された :math:`g(\vec{x})` の値の期待値およびその誤差から求められる「スコア」 (acquition function) が最適になるような点 :math:`\vec{x}_{N+1}` を次の計算候補点として提案します。
:math:`f(\vec{x}_{N+1})` を評価し、 訓練データセットに追加、 :math:`g` を再訓練します。
こうした探索を適当な回数繰り返した後、目的関数の値が最も良かったものを最適解として返します。

少ない誤差でより良い期待値を与える点は、正解である可能性こそ高いですが、すでに十分な情報があると考えられるので、モデル関数の精度向上にはあまり寄与しません。
逆に、誤差の大きな点は正解ではないかもしれませんが、情報の少ない場所であり、モデル関数の更新には有益だと考えられます。
前者を選ぶことを「活用」、後者を選ぶことを「探索」とよび、両者をバランス良く行うのが重要です。
「スコア」の定義はこれらをどう選ぶかを定めます。

2DMAT では、ベイズ最適化のライブラリとして、 `PHYSBO <https://github.com/issp-center-dev/PHYSBO>`_ を用います。
PHYSBO は ``mapper_mpi`` のように、あらかじめ決めておいた候補点の集合に対して「スコア」を計算して、最適解を提案します。
候補点の集合を分割することでMPI 並列実行が可能です。
また、 訓練データの点数 :math:`N` に対して線形の計算量でモデル関数の評価、ひいては「スコア」の計算が可能となるようなカーネルを用いています。
PHYSBO では「スコア」関数として "expected improvement (EI)", "probability of improvement (PI)", "Thompson sampling (TS)" が利用できます。

マルコフ連鎖モンテカルロ法
****************************

モンテカルロ法（モンテカルロサンプリング）では、パラメータ空間中を動き回る walker :math:`\vec{x}` を重み :math:`W(\vec{x})` に従って確率的に動かすことで目的関数の最適化を行います。
重み :math:`W(\vec{x})` として、「温度」 :math:`T > 0` を導入して :math:`W(\vec{x}) = e^{-f(\vec{x})/T}` とすることが一般的です（ボルツマン重み）。
ほとんどの場合において、 :math:`W` に基づいて直接サンプリングする (walker を生成する) のは不可能なので、 walker を確率的に少しずつ動かすことで、頻度分布が :math:`W` に従うように時系列 :math:`\{\vec{x}_t\}` を生成します (マルコフ連鎖モンテカルロ法, MCMC)。
:math:`\vec{x}` から :math:`\vec{x}'` へ遷移する確率を :math:`p(\vec{x}' | \vec{x})` とすると、

.. math::

  W(\vec{x}') = \sum_{\vec{x}} p(\vec{x}' | \vec{x}) W(\vec{x})

となるように :math:`p` を定めれば時系列 :math:`\{\vec{x}_t\}` の頻度分布が :math:`W(\vec{x})` に収束することが示されます（釣り合い条件） [#mcmc_condition]_ 。
実際の計算では、より強い制約である詳細釣り合い条件

.. math::

  p(\vec{x} | \vec{x}') W(\vec{x}') =  W(\vec{x})p(\vec{x}' | \vec{x})

を課すことがほとんどです。 両辺で :math:`vec{x}` についての和を取ると釣り合い条件に帰着します。

:math:`p` を求めるアルゴリズムはいくつか提案されていますが、 2DMAT では Metropolis-Hasting 法 (MH法) を用います。
MH 法では、遷移プロセスを提案プロセスと採択プロセスとに分割します。

1. 提案確率 :math:`P(\vec{x} | \vec{x}_t)` で候補点 :math:`\vec{x}` を生成します

   - 提案確率 :math:`P` としては :math:`\vec{x}_t` を中心とした一様分布やガウス関数などの扱いやすいものを利用します

2. 提案された候補点 :math:`\vec{x}` を採択確率 :math:`Q(\vec{x}, | \vec{x}_t)` で受け入れ、 :math:`\vec{x}_{t+1} = \vec{x}` とします
   - 受け入れなかった場合は :math:`\vec{x}_{t+1} = \vec{x}_t` とします

採択確率 :math:`Q(\vec{x} | \vec{x}_t)` は

.. math::

  Q(\vec{x} | \vec{x}_t) = \min\left[1, \frac{W(\vec{x})P(\vec{x}_t | \vec{x}) }{W(\vec{x}_t) P(\vec{x}_t | \vec{x})} \right]

とします。
この定義が詳細釣り合い条件を満たすことは、詳細釣り合いの式に代入することで簡単に確かめられます。
特に、重みとしてボルツマン因子を、
提案確率として対称なもの :math:`P(\vec{x} | \vec{x}_t) = P(\vec{x}_t | \vec{x})` を用いたときには、

.. math::

  Q(\vec{x} | \vec{x}_t) = \min\left[1, \frac{W(\vec{x})}{W(\vec{x}_t)} \right]
                         = \min\left[1, \exp\left(-\frac{f(\vec{x}) - f(\vec{x}_t)}{T}\right) \right]

という更に簡単な形になります。

:math:`\Delta f = f(\vec{x}) - f(\vec{x}_t)` とおいて、
:math:`\Delta f \le 0` のときに :math:`Q = 1` となることを踏まえると、
MH 法によるMCMC は次のようになります。

1. 現在地点の近くからランダムに次の座標の候補を選び、目的関数 :math:`f` の値を調べる
2. :math:`\Delta f \le 0` ならば（山を下る方向ならば）移動する
3. :math:`\Delta f > 0` ならば採択確率 :math:`Q = e^{-\Delta f / T}` で移動する
4. 1-3 を適当な回数繰り返す

得られた時系列のうち、目的関数の値が一番小さいものを最適解とします。
3 番のプロセスのおかげで、 :math:`\Delta f \sim T` ぐらいの山を乗り越えられるので、局所最適解にトラップされた場合にも脱出可能です。

レプリカ交換モンテカルロ法
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

モンテカルロ法による最適化では、温度 :math:`T` は非常に重要なハイパーパラメータとなっています。
モンテカルロ法では、温度 :math:`T` 程度の山を乗り越えられますが、逆にそれ以上の深さの谷からは容易に脱出できません。
そのため、局所解へのトラップを防ぐためには温度を上げる必要があります。
一方で、 :math:`T` よりも小さい谷は谷として見えなくなるため、得られる :math:`\min f(\vec{x})` の精度も :math:`T` 程度になり、精度を上げるためには温度を下げる必要があります。
ここから、最適解を探すためには温度 :math:`T` を注意深く決める必要があることがわかります。

この問題を解決する方法として、温度 :math:`T` を固定せずに更新していくというものがあります。
たとえば、焼きなまし法 (simulated annealing) では、温度をステップごとに徐々に下げていきます。
焼戻し法 (simulated tempering) は、温度をハイパーパラメータではなく、サンプリングすべきパラメータとして扱い、（詳細）釣り合い条件を満たすように更新することで、加熱と冷却を実現します。温度を下げることで谷の詳細を調べ、温度を上げることで谷から脱出します。
レプリカ交換モンテカルロ法 (replica exchange Monte Carlo) は焼戻し法を更に発展させた手法で、並列焼戻し法 (parallel tempering) とも呼ばれます。
レプリカ交換モンテカルロ法では、レプリカと呼ばれる複数の系を、それぞれ異なる温度で並列にモンテカルロシミュレーションします。
そして、ある一定間隔で、（詳細）釣り合い条件を満たすように他のレプリカと温度を交換します。
焼戻し法と同様に、温度を上下することで谷を調べたり脱出したりするのですが、各温度点について、かならずレプリカのどれかが対応しているため、全体として特定の温度に偏ることがなくなります。
また、一つのMPI プロセスに一つのレプリカを担当させることで簡単に並列化可能です。
数多くのレプリカを用意することで温度間隔が狭まると、温度交換の採択率も上がるため、大規模並列計算に特に向いたアルゴリズムです。
有限温度由来の「ぼやけ」がどうしても生まれるので、モンテカルロ法の結果を初期値として ``minsearch`` をするのがおすすめです。

.. rubric:: 脚注

.. [#mcmc_condition] 正確には、収束のためには非周期性とエルゴード性も必要です。
